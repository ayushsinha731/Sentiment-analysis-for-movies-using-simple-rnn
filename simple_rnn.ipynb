{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "907738bf-3719-4fe9-a827-3f040020a6c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split as tts\n",
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding,SimpleRNN, Dense,Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b5c8687-e480-48d4-8c95-fec6f33bd046",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4403d02c-0876-4f6b-a1fe-43a6439cea13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4355e8f7-0045-404b-b507-bc2647e20c31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape:(25000,), Training labels shape: (25000,)\n",
      "Testing data shape:(25000,), Testing labels shape:(25000,)\n"
     ]
    }
   ],
   "source": [
    "max_features = 10000 # vocab size\n",
    "(X_train,y_train),(X_test,y_test) = imdb.load_data(num_words=max_features)\n",
    "\n",
    "\n",
    "print(f'Training data shape:{X_train.shape}, Training labels shape: {y_train.shape}')\n",
    "print(f'Testing data shape:{X_test.shape}, Testing labels shape:{y_test.shape}')\n",
    "# usne test data ka toh kuch nhi kiya so i will be taking the charge to increase tha available data and epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "567f0075-955f-4b97-bb04-322681f6d4a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape:(45000,), Training labels shape: (45000,)\n",
      "Testing data shape:(5000,), Testing labels shape:(5000,)\n"
     ]
    }
   ],
   "source": [
    "# X=np.concatenate((X_train,X_test),axis = 0)\n",
    "# y=np.concatenate((y_train,y_test),axis = 0)\n",
    "\n",
    "# X_train,X_test,y_train,y_test = tts(X,y,test_size=0.2,random_state=42)   as we will be using cross validation ahead while training and all the data will be from same distribution.\n",
    "X=np.concatenate((X_train,X_test),axis = 0)\n",
    "y=np.concatenate((y_train,y_test),axis = 0)\n",
    "X_train, X_test, y_train, y_test = tts(X, y, test_size=0.1, random_state=43)\n",
    "\n",
    "print(f'Training data shape:{X_train.shape}, Training labels shape: {y_train.shape}')\n",
    "print(f'Testing data shape:{X_test.shape}, Testing labels shape:{y_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "520b5627-fd05-4cdd-84a9-ce76a7f49ee5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 2509,\n",
       " 1162,\n",
       " 7506,\n",
       " 5,\n",
       " 642,\n",
       " 13,\n",
       " 426,\n",
       " 570,\n",
       " 1104,\n",
       " 149,\n",
       " 14,\n",
       " 22,\n",
       " 5172,\n",
       " 2,\n",
       " 2423,\n",
       " 4,\n",
       " 102,\n",
       " 29,\n",
       " 93,\n",
       " 23,\n",
       " 4,\n",
       " 223,\n",
       " 5802,\n",
       " 1790,\n",
       " 56,\n",
       " 11,\n",
       " 2929,\n",
       " 2642,\n",
       " 11,\n",
       " 4,\n",
       " 5453,\n",
       " 45,\n",
       " 35,\n",
       " 221,\n",
       " 168,\n",
       " 33,\n",
       " 6,\n",
       " 8178,\n",
       " 1723,\n",
       " 5,\n",
       " 27,\n",
       " 4484,\n",
       " 5,\n",
       " 1256,\n",
       " 8,\n",
       " 8803,\n",
       " 18,\n",
       " 4,\n",
       " 370,\n",
       " 7673,\n",
       " 9,\n",
       " 6,\n",
       " 565,\n",
       " 681,\n",
       " 190,\n",
       " 92,\n",
       " 75,\n",
       " 32,\n",
       " 106,\n",
       " 102,\n",
       " 8,\n",
       " 30,\n",
       " 8282,\n",
       " 11,\n",
       " 49,\n",
       " 96,\n",
       " 42,\n",
       " 160,\n",
       " 10,\n",
       " 10,\n",
       " 39,\n",
       " 4,\n",
       " 454,\n",
       " 13,\n",
       " 16,\n",
       " 5184,\n",
       " 33,\n",
       " 4,\n",
       " 192,\n",
       " 15,\n",
       " 4,\n",
       " 1013,\n",
       " 11,\n",
       " 4,\n",
       " 108,\n",
       " 468,\n",
       " 8,\n",
       " 977,\n",
       " 2,\n",
       " 1945,\n",
       " 614,\n",
       " 303,\n",
       " 5172,\n",
       " 795,\n",
       " 44,\n",
       " 27,\n",
       " 8178,\n",
       " 6250,\n",
       " 5,\n",
       " 25,\n",
       " 70,\n",
       " 67,\n",
       " 12,\n",
       " 39,\n",
       " 4,\n",
       " 4199,\n",
       " 194,\n",
       " 4199,\n",
       " 7,\n",
       " 2,\n",
       " 33,\n",
       " 35,\n",
       " 402,\n",
       " 559,\n",
       " 279,\n",
       " 12,\n",
       " 16,\n",
       " 43,\n",
       " 4,\n",
       " 2272,\n",
       " 2929,\n",
       " 2642,\n",
       " 5825,\n",
       " 37,\n",
       " 694,\n",
       " 17,\n",
       " 6,\n",
       " 992,\n",
       " 132,\n",
       " 37,\n",
       " 82,\n",
       " 2083,\n",
       " 56,\n",
       " 11,\n",
       " 6,\n",
       " 2,\n",
       " 2776,\n",
       " 45,\n",
       " 87,\n",
       " 8,\n",
       " 67,\n",
       " 15,\n",
       " 27,\n",
       " 846,\n",
       " 5067,\n",
       " 5,\n",
       " 447,\n",
       " 90,\n",
       " 5,\n",
       " 15,\n",
       " 27,\n",
       " 369,\n",
       " 468,\n",
       " 8,\n",
       " 30,\n",
       " 2,\n",
       " 19,\n",
       " 27,\n",
       " 2,\n",
       " 676,\n",
       " 496,\n",
       " 4,\n",
       " 7315,\n",
       " 10,\n",
       " 10,\n",
       " 276,\n",
       " 4,\n",
       " 370,\n",
       " 23,\n",
       " 72,\n",
       " 1580,\n",
       " 6,\n",
       " 168,\n",
       " 145,\n",
       " 8,\n",
       " 4,\n",
       " 1355,\n",
       " 2,\n",
       " 34,\n",
       " 2,\n",
       " 490,\n",
       " 377,\n",
       " 4,\n",
       " 1153,\n",
       " 4,\n",
       " 228,\n",
       " 5,\n",
       " 4,\n",
       " 8160,\n",
       " 146,\n",
       " 4,\n",
       " 172,\n",
       " 559,\n",
       " 17,\n",
       " 443,\n",
       " 2,\n",
       " 38,\n",
       " 4,\n",
       " 1189,\n",
       " 145,\n",
       " 8,\n",
       " 1757,\n",
       " 2946,\n",
       " 16,\n",
       " 2378,\n",
       " 27,\n",
       " 4321,\n",
       " 5484,\n",
       " 2,\n",
       " 837,\n",
       " 612,\n",
       " 9,\n",
       " 4828,\n",
       " 6322,\n",
       " 34,\n",
       " 4,\n",
       " 5413,\n",
       " 271,\n",
       " 8,\n",
       " 363,\n",
       " 830,\n",
       " 3738,\n",
       " 10,\n",
       " 10,\n",
       " 4,\n",
       " 108,\n",
       " 855,\n",
       " 19,\n",
       " 465,\n",
       " 1326,\n",
       " 33,\n",
       " 58,\n",
       " 506,\n",
       " 2569,\n",
       " 4,\n",
       " 6224,\n",
       " 3478,\n",
       " 325,\n",
       " 861,\n",
       " 939,\n",
       " 5,\n",
       " 1031,\n",
       " 2,\n",
       " 57,\n",
       " 1548,\n",
       " 9,\n",
       " 340,\n",
       " 2,\n",
       " 5,\n",
       " 4,\n",
       " 96,\n",
       " 2,\n",
       " 2033,\n",
       " 19,\n",
       " 134,\n",
       " 4046,\n",
       " 9,\n",
       " 221,\n",
       " 8,\n",
       " 135,\n",
       " 4,\n",
       " 222,\n",
       " 5,\n",
       " 642,\n",
       " 8,\n",
       " 5599,\n",
       " 10,\n",
       " 10,\n",
       " 106,\n",
       " 33,\n",
       " 129,\n",
       " 7909,\n",
       " 2]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[0] ## one hot rep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "62d9017d-fbf9-42c6-b0f4-70a7a09123f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample review in number:[1, 48, 14, 22, 69, 6, 352, 7, 891, 1431, 474, 43, 40, 8, 124, 121, 4, 278, 435, 6, 3606, 100, 97, 128, 1683, 302, 95, 51, 16, 1053, 18, 342, 634, 23, 14, 2150, 418, 7, 1244, 261, 13, 215, 974, 4, 3869, 5, 4, 8254, 62, 28, 610, 66, 66, 646, 23, 35, 204, 297, 1709, 300, 500, 5, 402, 6090, 1628, 39, 4, 1696, 4773, 48, 6, 500, 69, 126, 77, 93, 51, 2, 72, 9, 121, 122, 4, 278, 140, 2, 108, 100, 28, 93, 6, 87, 22, 19, 52, 154, 3357, 4122, 5, 1222, 5407, 3965, 6, 1080, 742, 3651, 7962, 6592, 2, 5, 156, 37, 165, 168, 40, 36, 459, 44, 51, 36, 26, 399, 42, 7224, 11, 14, 420, 18, 44, 4, 172, 891, 1431, 14, 9, 179, 869, 4, 249, 22, 126, 93, 13, 62, 247, 870, 143, 6, 3333, 534, 3260, 2824, 7, 2, 74, 106, 14, 22, 174, 13, 1800, 12, 340, 13, 2, 13, 135, 14, 9, 4, 249, 22, 126, 93, 88, 1025, 85, 78, 102, 40, 1347, 790, 42, 455, 4808, 42, 2062, 5222, 2, 4, 8254, 134, 26, 108, 15, 26, 38, 78, 25, 28, 6, 318, 273, 11, 129, 483, 18, 98, 25, 119, 98, 50, 9, 57, 119, 18, 14, 22, 5, 57, 273, 11, 61, 288, 3323, 18, 12, 13, 2962, 12, 8, 6, 232, 18, 6, 2863, 146, 2, 4, 278, 18, 4, 22, 16, 1084, 23, 9691, 5, 85, 2, 18, 4, 177, 5, 1051, 902, 23, 25, 2, 108, 13, 181, 61, 278, 145] and its label:0\n"
     ]
    }
   ],
   "source": [
    "print(f\"Sample review in number:{X_train[0]} and its label:{y_train[0]}\")\n",
    "sample_review = X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "949d5a06-845c-453c-863b-2df7668c6ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = imdb.get_word_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "923f96f6-ae74-4a9a-8647-a0e56bfeeb86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "452057a4-6654-483e-af92-086f95282de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "rev_word_index = {value:key for key,value in word_index.items()}\n",
    "# rev_word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5679baa5-b0a5-472e-a991-99eb9a91fa5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"? if this film had a budget of 20 million i'd just like to know where the money went a monkey could make better cgi effects then what was wasted for 3 hours on this dreadful piece of garbage although i must admit the machines and the martians would have looked really really cool on an original play station 1 game and early pc games from the mid 90s if a game had ever been made what ? me is where did the money go ? films could have made a great film with good old fashioned models and computer controlled cameras a la george lucas circa 1975 ? and actors who actually look like they care about what they are doing or ruining in this case for about the same 20 million this is quite possibly the worst film ever made i would rather sit through a 24 hour repeat screening of ? than watch this film again i hated it completely i ? i say this is the worst film ever made because unlike other bad movies like plan 9 or killer tomatoes or santa claus ? the martians these are films that are so bad you have a special place in your heart for them you love them there is no love for this film and no place in my dvd library for it i sold it to a guy for a dollar i'm ? the money for the film was spent on booze and other ? for the cast and crew shame on you ? films i want my money back\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoded_review = ' '.join([rev_word_index.get(i - 3,'?') for i in sample_review])  # as in tf docs\n",
    "decoded_review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6823a07e-014b-4be7-bf64-088eb7ce8dea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    1, 2509, 1162, 7506,    5,\n",
       "        642,   13,  426,  570, 1104,  149,   14,   22, 5172,    2, 2423,\n",
       "          4,  102,   29,   93,   23,    4,  223, 5802, 1790,   56,   11,\n",
       "       2929, 2642,   11,    4, 5453,   45,   35,  221,  168,   33,    6,\n",
       "       8178, 1723,    5,   27, 4484,    5, 1256,    8, 8803,   18,    4,\n",
       "        370, 7673,    9,    6,  565,  681,  190,   92,   75,   32,  106,\n",
       "        102,    8,   30, 8282,   11,   49,   96,   42,  160,   10,   10,\n",
       "         39,    4,  454,   13,   16, 5184,   33,    4,  192,   15,    4,\n",
       "       1013,   11,    4,  108,  468,    8,  977,    2, 1945,  614,  303,\n",
       "       5172,  795,   44,   27, 8178, 6250,    5,   25,   70,   67,   12,\n",
       "         39,    4, 4199,  194, 4199,    7,    2,   33,   35,  402,  559,\n",
       "        279,   12,   16,   43,    4, 2272, 2929, 2642, 5825,   37,  694,\n",
       "         17,    6,  992,  132,   37,   82, 2083,   56,   11,    6,    2,\n",
       "       2776,   45,   87,    8,   67,   15,   27,  846, 5067,    5,  447,\n",
       "         90,    5,   15,   27,  369,  468,    8,   30,    2,   19,   27,\n",
       "          2,  676,  496,    4, 7315,   10,   10,  276,    4,  370,   23,\n",
       "         72, 1580,    6,  168,  145,    8,    4, 1355,    2,   34,    2,\n",
       "        490,  377,    4, 1153,    4,  228,    5,    4, 8160,  146,    4,\n",
       "        172,  559,   17,  443,    2,   38,    4, 1189,  145,    8, 1757,\n",
       "       2946,   16, 2378,   27, 4321, 5484,    2,  837,  612,    9, 4828,\n",
       "       6322,   34,    4, 5413,  271,    8,  363,  830, 3738,   10,   10,\n",
       "          4,  108,  855,   19,  465, 1326,   33,   58,  506, 2569,    4,\n",
       "       6224, 3478,  325,  861,  939,    5, 1031,    2,   57, 1548,    9,\n",
       "        340,    2,    5,    4,   96,    2, 2033,   19,  134, 4046,    9,\n",
       "        221,    8,  135,    4,  222,    5,  642,    8, 5599,   10,   10,\n",
       "        106,   33,  129, 7909,    2], dtype=int32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maxlen = 500\n",
    "X_train  = sequence.pad_sequences(X_train,maxlen=maxlen)\n",
    "X_test  = sequence.pad_sequences(X_test,maxlen=maxlen)\n",
    "X_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6c6dc62f-0060-415e-b4f1-e643b87f0872",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">500</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,280,000</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ simple_rnn (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SimpleRNN</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m500\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │     \u001b[38;5;34m1,280,000\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ simple_rnn (\u001b[38;5;33mSimpleRNN\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m32,896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu (\u001b[38;5;33mLeakyReLU\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu_1 (\u001b[38;5;33mLeakyReLU\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m65\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,321,985</span> (5.04 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,321,985\u001b[0m (5.04 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,321,601</span> (5.04 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,321,601\u001b[0m (5.04 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">384</span> (1.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m384\u001b[0m (1.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Train our simple rnn\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LeakyReLU, SimpleRNN, Embedding, Input,BatchNormalization\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "\n",
    "\n",
    "def custom_activation(x):\n",
    "    return (tf.nn.tanh(x) + 1) / 2\n",
    "\n",
    "l2_reg = regularizers.l2(0.01)\n",
    "\n",
    "dim = 128\n",
    "model = Sequential()\n",
    "model.add(Input((maxlen,)))\n",
    "model.add(Embedding(max_features, dim))\n",
    "model.add(SimpleRNN(128,kernel_regularizer=l2_reg))# 256 neurons in SimpleRNN\n",
    "model.add(BatchNormalization())\n",
    "model.add(LeakyReLU(negative_slope=0.1))  # LeakyReLU activation after SimpleRNN\n",
    "model.add(Dense(64,kernel_regularizer=l2_reg))  # 64 neurons in Dense layer\n",
    "model.add(BatchNormalization())\n",
    "model.add(LeakyReLU(negative_slope=0.1))  # LeakyReLU activation after Dense\n",
    "model.add(Dense(1, activation=custom_activation))  # Output layer for binary classification\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eedcd0e6-aebd-4c82-bf1d-7d7a495d2438",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile with lower learning rate and gradient clipping\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "optimizer = Adam(learning_rate=1e-3, clipnorm=1.0)\n",
    "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "88a9cf12-3867-448c-84b7-e7f0cb15bb71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.early_stopping.EarlyStopping at 0x105f51600>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create an instance of early stopping\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "earlystopping  = EarlyStopping(monitor='val_loss',patience=5, restore_best_weights=True)\n",
    "earlystopping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5c1938ec-2959-44f1-bac0-487178bd5439",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m317/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 229ms/step - accuracy: 0.5477 - loss: 2.2207 - val_accuracy: 0.4951 - val_loss: 1.5956\n",
      "Epoch 2/30\n",
      "\u001b[1m317/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 229ms/step - accuracy: 0.6260 - loss: 0.9157 - val_accuracy: 0.7702 - val_loss: 0.6241\n",
      "Epoch 3/30\n",
      "\u001b[1m317/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 225ms/step - accuracy: 0.8384 - loss: 0.4615 - val_accuracy: 0.8360 - val_loss: 0.4998\n",
      "Epoch 4/30\n",
      "\u001b[1m317/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 231ms/step - accuracy: 0.8757 - loss: 0.3384 - val_accuracy: 0.8460 - val_loss: 0.4425\n",
      "Epoch 5/30\n",
      "\u001b[1m317/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 230ms/step - accuracy: 0.8793 - loss: 0.3329 - val_accuracy: 0.8669 - val_loss: 0.4984\n",
      "Epoch 6/30\n",
      "\u001b[1m317/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 233ms/step - accuracy: 0.8919 - loss: 0.3115 - val_accuracy: 0.8604 - val_loss: 0.4062\n",
      "Epoch 7/30\n",
      "\u001b[1m317/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 225ms/step - accuracy: 0.9062 - loss: 0.2761 - val_accuracy: 0.8178 - val_loss: 0.4839\n",
      "Epoch 8/30\n",
      "\u001b[1m317/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 225ms/step - accuracy: 0.9050 - loss: 0.2898 - val_accuracy: 0.7340 - val_loss: 1.3681\n",
      "Epoch 9/30\n",
      "\u001b[1m317/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 223ms/step - accuracy: 0.9047 - loss: 0.2847 - val_accuracy: 0.8764 - val_loss: 0.3461\n",
      "Epoch 10/30\n",
      "\u001b[1m317/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 229ms/step - accuracy: 0.9165 - loss: 0.2512 - val_accuracy: 0.8142 - val_loss: 0.5000\n",
      "Epoch 11/30\n",
      "\u001b[1m317/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 229ms/step - accuracy: 0.9285 - loss: 0.2298 - val_accuracy: 0.8598 - val_loss: 0.3898\n",
      "Epoch 12/30\n",
      "\u001b[1m317/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 230ms/step - accuracy: 0.9310 - loss: 0.2180 - val_accuracy: 0.8756 - val_loss: 0.4038\n",
      "Epoch 13/30\n",
      "\u001b[1m317/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 229ms/step - accuracy: 0.9359 - loss: 0.2047 - val_accuracy: 0.8676 - val_loss: 0.3620\n",
      "Epoch 14/30\n",
      "\u001b[1m317/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 232ms/step - accuracy: 0.9367 - loss: 0.2078 - val_accuracy: 0.8440 - val_loss: 0.4517\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Train the model with early stopping \n",
    "history = model.fit(\n",
    "    X_train, y_train, epochs=30, batch_size=128, \n",
    "    validation_split=0.1, \n",
    "    callbacks=[earlystopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ab4cb087-271a-4e4d-a817-c26b894c7069",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step\n",
      "Accuracy: 0.8598\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Get model predictions\n",
    "y_hat = model.predict(X_test)\n",
    "\n",
    "# Convert probabilities to binary predictions (0 or 1)\n",
    "y_pred = (y_hat > 0.50).astype(int)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "42c79ab7-a912-4ee9-b029-eeb4f595d905",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('simple_rnn_model.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b57106dc-e204-46e3-9156-409f0130c87e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8598\n"
     ]
    }
   ],
   "source": [
    "y_pred = (y_hat > 0.5).astype(int)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c23330f-90ed-46a8-9bc1-aa16a7766aa1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db67f5b-ce65-4c2d-9364-9794d5ef9487",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f82f6297-c20f-4ff6-a673-0a2838b79e7c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
